{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort data into training and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions from other notebook\n",
    "from ipynb.fs.full.YCAC_metric_type_functions import *\n",
    "from ipynb.fs.full.YCAC_metric_type_functions import extractPieceSlicesAndDFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where you put the csv file\n",
    "file = \"/Users/matthewchiu/Documents/YCAC/YCAC-data-1/BachSlices.csv\"\n",
    "bach = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set weighting to subdivisional grids and take DFT of randomized windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions used:<br> <br> gridifyM21 — makes music into a grid format: parameters(YCAC_file, name of pieces, subdivision grid) <br> <br> extractPieceSlicesAndDFTs — randomly selects slices from grids: parameters(gridified music, #ofSlices, length of slice) <br> <br> dftSlices — returns DFT of slices as [magnitude, squared then normalized mags, phase, complex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign duration weight2\n",
      "Assign window for register check3\n",
      "Assign weight for lowest pitch in window6\n",
      "Excel parsed and pieces extracted\n",
      "Chords ready to be formatted\n",
      "weighting process starting\n",
      "starting grids\n",
      "okay\n"
     ]
    }
   ],
   "source": [
    "allemandeGrids = pieceTypes.gridifyM21Chords(bach, \"allemande\", .125)\n",
    "allemandeSlices = dftSlices(extractPieceSlicesAndDFTs(allemandeGrids, 1000, 96))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign duration weight2\n",
      "Assign window for register check3\n",
      "Assign weight for lowest pitch in window6\n",
      "Excel parsed and pieces extracted\n",
      "Chords ready to be formatted\n",
      "weighting process starting\n",
      "starting grids\n"
     ]
    }
   ],
   "source": [
    "couranteGrids = pieceTypes.gridifyM21Chords(bach, \"courante\", .125)\n",
    "couranteSlices = dftSlices(extractPieceSlicesAndDFTs(couranteGrids, 1000, 96))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign duration weight2\n",
      "Assign window for register check3\n",
      "Assign weight for lowest pitch in window6\n",
      "Excel parsed and pieces extracted\n",
      "Chords ready to be formatted\n",
      "weighting process starting\n",
      "starting grids\n"
     ]
    }
   ],
   "source": [
    "sarabandeGrids = pieceTypes.gridifyM21Chords(bach, \"sarabande\", .125)\n",
    "sarabandeSlices = dftSlices(extractPieceSlicesAndDFTs(sarabandeGrids, 1000, 96))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assign duration weight2\n",
      "Assign window for register check3\n",
      "Assign weight for lowest pitch in window6\n",
      "Excel parsed and pieces extracted\n",
      "Chords ready to be formatted\n",
      "weighting process starting\n",
      "starting grids\n"
     ]
    }
   ],
   "source": [
    "gavotteGrids = pieceTypes.gridifyM21Chords(bach, \"gavotte\", .125)\n",
    "gavotteSlices = dftSlices(extractPieceSlicesAndDFTs(gavotteGrids, 1000, 96))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allemandeDataFrame = dataFrameWithTargets(allemandeSlices, \"allemande\")\n",
    "couranteDataFrame = dataFrameWithTargets(couranteSlices, \"courante\")\n",
    "sarabandeDataFrame = dataFrameWithTargets(sarabandeSlices, \"sarabande\")\n",
    "gavotteDataFrame = dataFrameWithTargets(gavotteSlices, \"gavotte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWindows = allemandeDataFrame.append(couranteDataFrame)\n",
    "allWindows = allWindows.append(sarabandeDataFrame)\n",
    "allWindows = allWindows.append(gavotteDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data extracted from allWindows\n",
    "\n",
    "trainingData = allWindows[0:950]\n",
    "trainingData2 = allWindows[1000:1950]\n",
    "trainingData3 = allWindows[2000:2950]\n",
    "trainingData4 = allWindows[3000:3950]\n",
    "trainingFrames = [trainingData, trainingData2, trainingData3, trainingData4]\n",
    "\n",
    "testData = allWindows[950:1000]\n",
    "testData2 = allWindows[1950:2000]\n",
    "testData3 = allWindows[2950:3000]\n",
    "testData4 = allWindows[3950:4000]\n",
    "testFrames = [testData, testData2, testData3, testData4]\n",
    "\n",
    "trainingData = pd.concat(trainingFrames)\n",
    "testData = pd.concat(testFrames)\n",
    "\n",
    "trainingData['target'] = pd.Categorical(trainingData['target'])\n",
    "trainingData['target'] = trainingData.target.cat.codes\n",
    "target = trainingData.pop('target')\n",
    "target = oneHotCategories(target)\n",
    "# Set components below—I just included first half (without f0,f1)\n",
    "trainingData = trainingData.iloc[:, 2:98]\n",
    "\n",
    "testData['target'] = pd.Categorical(testData['target'])\n",
    "testData['target'] = testData.target.cat.codes\n",
    "testTarget = testData.pop('target')\n",
    "testTarget = oneHotCategories(testTarget)\n",
    "# Set components below—I just included first half (without f0,f1)\n",
    "testData = testData.iloc[:, 2:98]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((trainingData.values, target[0]))\n",
    "train_dataset = dataset.shuffle(len(trainingData)).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model parameters are currently set to 3 levels after being fed in from components: 30->10->4. <br> Where the output (4) is the probability distribution (made by softmax function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(30, activation='selu'),\n",
    "        tf.keras.layers.Dense(10, activation='selu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3800/3800 [==============================] - 2s 549us/step - loss: 1.1771 - accuracy: 0.4593\n",
      "Epoch 2/10\n",
      "3800/3800 [==============================] - 2s 536us/step - loss: 0.8614 - accuracy: 0.6178\n",
      "Epoch 3/10\n",
      "3800/3800 [==============================] - 2s 536us/step - loss: 0.8003 - accuracy: 0.6591\n",
      "Epoch 4/10\n",
      "3800/3800 [==============================] - 2s 529us/step - loss: 0.7665 - accuracy: 0.6824\n",
      "Epoch 5/10\n",
      "3800/3800 [==============================] - 2s 536us/step - loss: 0.7238 - accuracy: 0.6783\n",
      "Epoch 6/10\n",
      "3800/3800 [==============================] - 2s 553us/step - loss: 0.6951 - accuracy: 0.7065\n",
      "Epoch 7/10\n",
      "3800/3800 [==============================] - 2s 533us/step - loss: 0.6601 - accuracy: 0.7344\n",
      "Epoch 8/10\n",
      "3800/3800 [==============================] - 2s 530us/step - loss: 0.6550 - accuracy: 0.7320\n",
      "Epoch 9/10\n",
      "3800/3800 [==============================] - 2s 542us/step - loss: 0.6447 - accuracy: 0.7387\n",
      "Epoch 10/10\n",
      "3800/3800 [==============================] - 2s 548us/step - loss: 0.6239 - accuracy: 0.7473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9045baad30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3800/3800 [==============================] - 2s 556us/step - loss: 0.6148 - accuracy: 0.7442\n",
      "Epoch 2/3\n",
      "3800/3800 [==============================] - 2s 557us/step - loss: 0.6040 - accuracy: 0.7505\n",
      "Epoch 3/3\n",
      "3800/3800 [==============================] - 2s 555us/step - loss: 0.5957 - accuracy: 0.7558\n",
      "Evaluate\n",
      "200/200 [==============================] - 0s 635us/step - loss: 0.6635 - accuracy: 0.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.6635404825210571, 'accuracy': 0.7099999785423279}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we evaluate the model with the separated testing data\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((testData.values, testTarget[0]))\n",
    "test_dataset = test_dataset.batch(1)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing independent cases (to show outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareForIndependentTests(testData):\n",
    "    testData = testData\n",
    "    target = testData.pop(\"target\")\n",
    "    target = oneHotCategories(target)\n",
    "    target = np.array(target[0])\n",
    "    testData = testData.iloc[0,2:98]\n",
    "    testData = np.array([testData])\n",
    "    \n",
    "    return testData, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitiate the data since \"pop\" function reshapes arrays\n",
    "trainingData = allWindows[0:950]\n",
    "trainingData2 = allWindows[1000:1950]\n",
    "trainingData3 = allWindows[2000:2950]\n",
    "trainingData4 = allWindows[3000:3950]\n",
    "trainingFrames = [trainingData, trainingData2, trainingData3, trainingData4]\n",
    "\n",
    "testData = allWindows[950:1000]\n",
    "testData2 = allWindows[1950:2000]\n",
    "testData3 = allWindows[2950:3000]\n",
    "testData4 = allWindows[3950:4000]\n",
    "testFrames = [testData, testData2, testData3, testData4]\n",
    "\n",
    "trainingData = pd.concat(trainingFrames)\n",
    "testData = pd.concat(testFrames)\n",
    "\n",
    "trainingData['target'] = pd.Categorical(trainingData['target'])\n",
    "trainingData['target'] = trainingData.target.cat.codes\n",
    "testData['target'] = pd.Categorical(testData['target'])\n",
    "testData['target'] = testData.target.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "allemandeTest = prepareForIndependentTests(testData[0:1])\n",
    "couranteTest = prepareForIndependentTests(testData[50:51])\n",
    "sarabandeTest = prepareForIndependentTests(testData[100:101])\n",
    "gavotteTest = prepareForIndependentTests(testData[150:151])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[allemande, courante, gavotte, sarabande]\n",
      "\n",
      "allemande prediction\n",
      "[[9.96744037e-01 2.51641101e-03 1.14682625e-04 6.24904234e-04]]\n",
      "\n",
      "courante prediction\n",
      "[[0.5687523  0.18129535 0.00154676 0.24840559]]\n",
      "\n",
      "sarabande prediction\n",
      "[[0.0139293  0.14060032 0.00175025 0.84372014]]\n",
      "\n",
      "gavotte prediction\n",
      "[[2.3599740e-03 7.5848965e-07 9.9763906e-01 2.8779084e-07]]\n"
     ]
    }
   ],
   "source": [
    "print(\"[allemande, courante, gavotte, sarabande]\")\n",
    "print(\"\")\n",
    "print(\"allemande prediction\")\n",
    "print(model.predict(allemandeTest[0]))\n",
    "\n",
    "print(\"\")\n",
    "print(\"courante prediction\")\n",
    "print(model.predict(couranteTest[0]))\n",
    "\n",
    "print(\"\")\n",
    "print(\"sarabande prediction\")\n",
    "print(model.predict(sarabandeTest[0]))\n",
    "\n",
    "print(\"\")\n",
    "print(\"gavotte prediction\")\n",
    "print(model.predict(gavotteTest[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction is respectively: allemande, allemande, sarabande, gavotte (only messing up courante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003261249279603362, 1.0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate shows accuracy, whereas predict shows output\n",
    "model.evaluate(allemandeTest[0],allemandeTest[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
